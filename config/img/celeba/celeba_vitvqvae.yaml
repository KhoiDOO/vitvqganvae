name: celeba_vitvqvae
exp_root_dir: outputs
exp_dir: ""
trial_dir: ""
n_gpus: 1
seed: 42

dataset_name: celeba
dataset_source: torchvision
dataset_img_key: null
dataset_kwargs:
  root: ./.cache/${dataset_name}
  download: True
  image_size: 64

model: ImgVITVQVAE
model_config: ImgVITVQVAEConfig
model_kwargs:
  image_size: ${dataset_kwargs.image_size}
  patch_size: 4
  in_channel: 3
  out_channel: 3
  dim: 128
  depth: 4
  heads: 6
  encoder_attn_kwargs:
    attn_flash: True
    attn_num_mem_kv: 16
    attn_qk_norm: true
    pre_norm: true
    ff_glu: true
    ff_no_bias: true
  decoder_attn_kwargs:
    attn_flash: True
    attn_num_mem_kv: 16
    attn_qk_norm: true
    pre_norm: true
    ff_glu: true
    ff_no_bias: true
  quantizer: "VectorQuantize"
  codebook_size: 512
  quantizer_kwargs: {
    "codebook_dim": 64,
    "decay" : 0.99,
    "commitment_weight": 0.25,
    "kmeans_init": True,
    "use_cosine_sim": True
  }
  l2_recon_loss: True

trainer: VQVAETrainer
trainer_config: VQVAETrainerConfig
trainer_kwargs:
  num_train_steps: 300000
  batch_size: 128
  num_workers: 16
  pin_memory: True
  grad_accum_every: 1
  learning_rate: 0.001
  weight_decay: 0.
  max_grad_norm: 0.5
  val_every: 1000
  val_num_batches: 20
  val_num_images: 32
  scheduler: CosineAnnealingLR
  scheduler_kwargs:
    T_max: "${sub: ${trainer_kwargs.num_train_steps}, ${trainer_kwargs.warmup_steps}}"
    eta_min: 0.0005
  ema_kwargs: null
  accelerator_kwargs: {}
  optimizer_name: Adam
  optimizer_kwargs: {}
  loss_lambda:
    recon_loss: 1.
    quantizer_loss: 1.
  checkpoint_every: 1000
  save_results_every: null
  warmup_steps: 0
  use_wandb_tracking: False
  resume: False
  from_checkpoint: null
  from_checkpoint_type: null

wandb:
  project_name: "vitvqganvae"
  run_name: null
  kwargs:
    entity: "heartbeats"